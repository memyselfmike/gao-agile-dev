Create a comprehensive PRD for the "E2E Testing & UX Quality Analysis System" feature.

**CONTEXT:**
GAO-Dev now has an interactive Brian chat interface (gao-dev start) from Epic 30, with provider selection from Epic 35. The first beta release has been deployed. Users are finding bugs and UX issues related to Brian's understanding of user intent, natural probing for details, and conversation quality.

**PROBLEM:**
1. No E2E testing for the interactive chat experience (only unit/integration tests with mocks)
2. Cannot test real user experience with subprocess execution
3. No framework to analyze conversation quality and identify UX deficiencies
4. No way for developers (including AI like Claude) to interact with gao-dev start programmatically to debug issues
5. Expensive to run tests with Claude API - need cost-free testing solution

**SOLUTION REQUIREMENTS:**

**1. Cost-Free Testing Infrastructure**
- ALL tests must default to opencode provider with ollama/deepseek-r1 model
- Zero API costs for development and CI/CD
- Environment variable override for occasional Claude API testing
- Fast local execution (<2s per test)

**2. Three-Mode Testing System**

MODE 1: Interactive Debug (Claude ↔ Brian)
- Framework for Claude Code to spawn gao-dev start and interact with Brian
- Real AI responses (not mocked)
- Full conversation capture with instrumentation
- Claude analyzes UX quality and generates improvement reports
- Iterative: Test → Analyze → Fix → Retest

MODE 2: Conversation Quality Analysis
- Analyze conversation transcripts for UX issues
- Identify: poor intent understanding, missed probing opportunities, unused context
- Generate actionable recommendations with specific examples
- Quality scoring system
- Pattern detection (common failure modes)

MODE 3: Automated Regression Tests
- Fixture-based tests with scripted scenarios
- Pattern matching on subprocess output (with ANSI stripping)
- CI/CD compatible (headless, deterministic, parallel)
- Convert good conversations to regression tests

**3. Technical Requirements**
- Use pexpect/wexpect for subprocess interaction (Windows compatible)
- Capture mode: Instrument ChatSession for full conversation logging
- Test mode: Support fixture loading for deterministic scenarios
- Output verification: ANSI-aware pattern matching
- Conversation analysis: AI-powered quality assessment

**4. User Stories**
- As a developer, I want to run E2E tests locally with zero API cost
- As Claude Code, I want to interact with gao-dev start to identify and analyze UX issues  
- As a developer, I want quality reports highlighting specific conversation deficiencies
- As a QA engineer, I want automated regression tests that prevent UX quality degradation
- As a developer, I want to convert real user sessions into test fixtures

**5. Success Criteria**
- 100% of tests use opencode/ollama/deepseek-r1 by default
- Claude can spawn and interact with Brian programmatically
- Quality analyzer generates actionable UX improvement reports
- 20+ E2E test scenarios (greenfield, brownfield, errors, edge cases)
- <5% test execution overhead vs. manual testing
- CI/CD integration with headless execution
- Zero regressions in existing 400+ tests

**6. Out of Scope (Future Work)**
- Performance benchmarking of conversation response times
- Multi-user concurrent chat testing
- Voice/audio interface testing
- Mobile app testing

**7. Technical Constraints**
- Must work on Windows, macOS, Linux
- Must not require Anthropic API key for default operation
- Must integrate with existing provider abstraction (Epic 21, Epic 35)
- Must preserve conversation privacy (no external logging)

Generate a comprehensive PRD following GAO-Dev's standard format with:
- Executive Summary
- Problem Statement
- Solution Overview
- Functional Requirements
- Non-Functional Requirements
- User Stories
- Success Criteria
- Timeline & Milestones
